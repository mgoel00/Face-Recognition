{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the faces from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the person: asdf\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# Define Image Path Here\n",
    "Class_Name = input(\"Enter the name of the person: \")\n",
    "train_path = \"./faces/train/\" + Class_Name\n",
    "validation_path = \"./faces/validation/\" + Class_Name\n",
    "os.mkdir(train_path)\n",
    "os.mkdir(validation_path)\n",
    "\n",
    "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               font_scale=0.8, thickness=1):\n",
    "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
    "    x, y = point\n",
    "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness)\n",
    "    \n",
    "# Use the efficient dlib's face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "img_size = 64\n",
    "margin = 0.2\n",
    "frame_count = 0\n",
    "\n",
    "#Capture 70 images of a class with 50 test and 20 validation images\n",
    "while frame_count != 70:\n",
    "    \n",
    "    ret, frame = cap.read()  \n",
    "    input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w, _ = np.shape(input_img)\n",
    "    detected = detector(frame, 1)\n",
    "\n",
    "    if len(detected) > 0:     #means face is detected\n",
    "        frame_count += 1\n",
    "        \n",
    "        for i, d in enumerate(detected):\n",
    "            # Obtain the coordinates of the detected face\n",
    "            x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n",
    "            xw1 = max(int(x1 - margin * w), 0)\n",
    "            yw1 = max(int(y1 - margin * h), 0)\n",
    "            xw2 = min(int(x2 + margin * w), img_w - 1)\n",
    "            yw2 = min(int(y2 + margin * h), img_h - 1)\n",
    "            face =  frame[yw1:yw2 + 1, xw1:xw2 + 1, :]\n",
    "            \n",
    "            #Saving the obtained face images\n",
    "            if frame_count > 50:\n",
    "                file_name = validation_path + '/' + str(frame_count)+\".jpg\"\n",
    "            else:\n",
    "                file_name = train_path + '/' + str(frame_count)+\".jpg\"\n",
    "                \n",
    "            cv2.imwrite(file_name, face)\n",
    "            draw_label(frame,(x1,y1),str(frame_count))\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Face Detector\", frame)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
